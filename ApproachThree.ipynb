{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (2.0.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (3.8.1)\n",
      "Requirement already satisfied: emoji in c:\\program files\\python311\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: click in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (8.1.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.21.0-cp311-cp311-win_amd64.whl (22.8 MB)\n",
      "                                              0.0/22.8 MB ? eta -:--:--\n",
      "                                              0.0/22.8 MB 1.4 MB/s eta 0:00:17\n",
      "                                              0.1/22.8 MB 1.3 MB/s eta 0:00:18\n",
      "                                              0.2/22.8 MB 1.6 MB/s eta 0:00:15\n",
      "                                              0.3/22.8 MB 1.9 MB/s eta 0:00:13\n",
      "     -                                        0.7/22.8 MB 2.8 MB/s eta 0:00:08\n",
      "     -                                        1.0/22.8 MB 3.4 MB/s eta 0:00:07\n",
      "     --                                       1.2/22.8 MB 3.7 MB/s eta 0:00:06\n",
      "     --                                       1.7/22.8 MB 4.2 MB/s eta 0:00:05\n",
      "     ---                                      2.1/22.8 MB 4.6 MB/s eta 0:00:05\n",
      "     ----                                     2.4/22.8 MB 4.8 MB/s eta 0:00:05\n",
      "     -----                                    3.0/22.8 MB 5.2 MB/s eta 0:00:04\n",
      "     -----                                    3.3/22.8 MB 5.2 MB/s eta 0:00:04\n",
      "     ------                                   3.8/22.8 MB 5.5 MB/s eta 0:00:04\n",
      "     -------                                  4.2/22.8 MB 5.6 MB/s eta 0:00:04\n",
      "     -------                                  4.5/22.8 MB 5.6 MB/s eta 0:00:04\n",
      "     --------                                 4.8/22.8 MB 5.7 MB/s eta 0:00:04\n",
      "     ---------                                5.2/22.8 MB 5.7 MB/s eta 0:00:04\n",
      "     ---------                                5.5/22.8 MB 5.8 MB/s eta 0:00:03\n",
      "     ----------                               5.9/22.8 MB 5.8 MB/s eta 0:00:03\n",
      "     -----------                              6.4/22.8 MB 5.9 MB/s eta 0:00:03\n",
      "     -----------                              6.6/22.8 MB 5.9 MB/s eta 0:00:03\n",
      "     ------------                             7.0/22.8 MB 6.0 MB/s eta 0:00:03\n",
      "     ------------                             7.3/22.8 MB 6.0 MB/s eta 0:00:03\n",
      "     -------------                            7.7/22.8 MB 6.0 MB/s eta 0:00:03\n",
      "     --------------                           8.1/22.8 MB 6.1 MB/s eta 0:00:03\n",
      "     --------------                           8.4/22.8 MB 6.1 MB/s eta 0:00:03\n",
      "     ---------------                          8.7/22.8 MB 6.1 MB/s eta 0:00:03\n",
      "     ----------------                         9.2/22.8 MB 6.2 MB/s eta 0:00:03\n",
      "     ----------------                         9.6/22.8 MB 6.2 MB/s eta 0:00:03\n",
      "     -----------------                        10.0/22.8 MB 6.3 MB/s eta 0:00:03\n",
      "     ------------------                       10.3/22.8 MB 6.5 MB/s eta 0:00:02\n",
      "     ------------------                       10.6/22.8 MB 6.9 MB/s eta 0:00:02\n",
      "     -------------------                      11.0/22.8 MB 6.8 MB/s eta 0:00:02\n",
      "     --------------------                     11.4/22.8 MB 6.9 MB/s eta 0:00:02\n",
      "     --------------------                     11.8/22.8 MB 6.9 MB/s eta 0:00:02\n",
      "     ---------------------                    12.2/22.8 MB 6.9 MB/s eta 0:00:02\n",
      "     ---------------------                    12.5/22.8 MB 6.8 MB/s eta 0:00:02\n",
      "     ----------------------                   12.8/22.8 MB 7.0 MB/s eta 0:00:02\n",
      "     -----------------------                  13.2/22.8 MB 6.8 MB/s eta 0:00:02\n",
      "     ------------------------                 13.7/22.8 MB 7.0 MB/s eta 0:00:02\n",
      "     ------------------------                 14.0/22.8 MB 7.0 MB/s eta 0:00:02\n",
      "     -------------------------                14.4/22.8 MB 6.9 MB/s eta 0:00:02\n",
      "     -------------------------                14.7/22.8 MB 6.9 MB/s eta 0:00:02\n",
      "     --------------------------               15.0/22.8 MB 6.7 MB/s eta 0:00:02\n",
      "     ---------------------------              15.5/22.8 MB 6.9 MB/s eta 0:00:02\n",
      "     ---------------------------              15.8/22.8 MB 6.8 MB/s eta 0:00:02\n",
      "     ----------------------------             16.2/22.8 MB 6.9 MB/s eta 0:00:01\n",
      "     ----------------------------             16.4/22.8 MB 6.7 MB/s eta 0:00:01\n",
      "     -----------------------------            16.7/22.8 MB 6.8 MB/s eta 0:00:01\n",
      "     ------------------------------           17.1/22.8 MB 6.7 MB/s eta 0:00:01\n",
      "     -------------------------------          17.6/22.8 MB 6.8 MB/s eta 0:00:01\n",
      "     -------------------------------          18.1/22.8 MB 6.8 MB/s eta 0:00:01\n",
      "     --------------------------------         18.5/22.8 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------        18.9/22.8 MB 6.8 MB/s eta 0:00:01\n",
      "     ----------------------------------       19.5/22.8 MB 6.8 MB/s eta 0:00:01\n",
      "     -----------------------------------      19.9/22.8 MB 6.7 MB/s eta 0:00:01\n",
      "     -----------------------------------      20.4/22.8 MB 6.8 MB/s eta 0:00:01\n",
      "     ------------------------------------     20.8/22.8 MB 6.7 MB/s eta 0:00:01\n",
      "     -------------------------------------    21.3/22.8 MB 6.8 MB/s eta 0:00:01\n",
      "     --------------------------------------   21.7/22.8 MB 6.8 MB/s eta 0:00:01\n",
      "     --------------------------------------   22.0/22.8 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  22.4/22.8 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  22.7/22.8 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  22.8/22.8 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  22.8/22.8 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  22.8/22.8 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  22.8/22.8 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  22.8/22.8 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  22.8/22.8 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 22.8/22.8 MB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from scikit-image) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from scikit-image) (1.11.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from scikit-image) (10.0.0)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from scikit-image) (2.31.1)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2023.7.18-py3-none-any.whl (221 kB)\n",
      "                                              0.0/221.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 221.4/221.4 kB 6.8 MB/s eta 0:00:00\n",
      "Collecting PyWavelets>=1.1.1 (from scikit-image)\n",
      "  Downloading PyWavelets-1.4.1-cp311-cp311-win_amd64.whl (4.2 MB)\n",
      "                                              0.0/4.2 MB ? eta -:--:--\n",
      "     ----                                     0.5/4.2 MB 7.3 MB/s eta 0:00:01\n",
      "     -------                                  0.8/4.2 MB 7.4 MB/s eta 0:00:01\n",
      "     -----------                              1.2/4.2 MB 6.9 MB/s eta 0:00:01\n",
      "     ---------------                          1.6/4.2 MB 7.0 MB/s eta 0:00:01\n",
      "     -------------------                      2.0/4.2 MB 7.3 MB/s eta 0:00:01\n",
      "     -----------------------                  2.4/4.2 MB 7.3 MB/s eta 0:00:01\n",
      "     -------------------------                2.7/4.2 MB 7.1 MB/s eta 0:00:01\n",
      "     ----------------------------             3.0/4.2 MB 7.1 MB/s eta 0:00:01\n",
      "     --------------------------------         3.4/4.2 MB 6.9 MB/s eta 0:00:01\n",
      "     -------------------------------------    3.9/4.2 MB 7.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  4.1/4.2 MB 7.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  4.2/4.2 MB 6.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.2/4.2 MB 6.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from scikit-image) (23.1)\n",
      "Collecting lazy_loader>=0.2 (from scikit-image)\n",
      "  Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Installing collected packages: tifffile, PyWavelets, lazy_loader, scikit-image\n",
      "Successfully installed PyWavelets-1.4.1 lazy_loader-0.3 scikit-image-0.21.0 tifffile-2023.7.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas nltk emoji\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_excel('train1.xlsx')\n",
    "df_test = pd.read_excel('test1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['image_name'] = df_train['post_id'].astype(str) + '.jpg'\n",
    "df_test['image_name'] = df_test['post_id'].astype(str) + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns using the 'select_dtypes()' method\n",
    "df_train_numeric = df_train.select_dtypes(include=['int64', 'float64'])\n",
    "df_test_numeric = df_test.select_dtypes(include=['int64', 'float64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as sk_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqGenerator(X_train, y_train, batch_size, image_directory, df):\n",
    "    index = 0\n",
    "    num_train = X_train.shape[0]\n",
    "    \n",
    "    while True:\n",
    "        images_batch = []\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            # Get the image name from the DataFrame\n",
    "            image_name = df['image_name'].iloc[index]\n",
    "            \n",
    "            # Load the image from the local folder\n",
    "            image_path = os.path.join(image_directory, image_name)\n",
    "            img = io.imread(image_path)\n",
    "            # Assuming you have defined IMAGE_SIZE and CHANNELS previously\n",
    "            img = sk_transform.resize(img, (IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
    "            img = img / 255.0  # Normalize the image\n",
    "            \n",
    "            images_batch.append(img)\n",
    "            x_batch.append(X_train.iloc[index])  # Access the DataFrame correctly by using iloc\n",
    "            y_batch.append(y_train.iloc[index])  # Access the DataFrame correctly by using iloc\n",
    "            \n",
    "            # Update the index and handle wrapping around the dataset\n",
    "            index = (index + 1) % num_train\n",
    "        \n",
    "        images_batch = np.asarray(images_batch)\n",
    "        x_batch = np.asarray(x_batch)\n",
    "        y_batch = np.asarray(y_batch)\n",
    "        \n",
    "        yield [images_batch, x_batch], y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X_train, X_test = df_train_numeric.iloc[:, :-1], df_test_numeric.iloc[:, :-1]  # Features (all columns except the last one)\n",
    "y_train, y_test = df_train_numeric.iloc[:, -1], df_test_numeric.iloc[:, -1]   # Target variable (last column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df=pd.concat([df_train,df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>num_followers</th>\n",
       "      <th>num_followings</th>\n",
       "      <th>post_id</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>caption</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>hashtag_score</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>num_likes</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leanna_markoglou</td>\n",
       "      <td>23791</td>\n",
       "      <td>615</td>\n",
       "      <td>BTJVjFOAZRC</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>makeup, hairstyle, youmagazine, photoshooting,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My beauty friend.!! #makeup #hairstyle #youmag...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>60654</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>521</td>\n",
       "      <td>BTJVjFOAZRC.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jls_by_dimitra</td>\n",
       "      <td>14001</td>\n",
       "      <td>1673</td>\n",
       "      <td>BSnouCMl9dx</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Πενταπλο βραχιολι \"χειροπεδα \" με μαγνητικό κο...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7633</td>\n",
       "      <td>401</td>\n",
       "      <td>BSnouCMl9dx.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cookingnetwork</td>\n",
       "      <td>15040</td>\n",
       "      <td>3415</td>\n",
       "      <td>BStIhYmAa4Z</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>puremagic, kayak_ice_cream, icecream, lemon, l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lemon Grass Ice Cream 🍋 #puremagic #kayak_ice_...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>51521</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>108</td>\n",
       "      <td>BStIhYmAa4Z.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>annamariabarouh</td>\n",
       "      <td>12761</td>\n",
       "      <td>42</td>\n",
       "      <td>BSzRv3gD9Yx</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>easter, pastel, cupcakes, adorable, delicious</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Easter is coming#Easter#pastel #cupcakes #ador...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>37419</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>250</td>\n",
       "      <td>BSzRv3gD9Yx.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>olgafarmaki</td>\n",
       "      <td>188519</td>\n",
       "      <td>997</td>\n",
       "      <td>BTPQT0Hl4pk</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>clubc, reebokgreece, sneakers, sparkle, detail...</td>\n",
       "      <td>reebokgreece</td>\n",
       "      <td>Just the right amount of sparkle @reebokgreece...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>25564</td>\n",
       "      <td>1.4215</td>\n",
       "      <td>5168</td>\n",
       "      <td>BTPQT0Hl4pk.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>twinsfashionn</td>\n",
       "      <td>17690</td>\n",
       "      <td>4121</td>\n",
       "      <td>BTNBi0cBapl</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>twinsfashion, invernotwins, bonslooks, shopnow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Colete faux fur maravideuso 💗 SHOP NOW 📲www.tw...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>92</td>\n",
       "      <td>BTNBi0cBapl.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>dorisliapata</td>\n",
       "      <td>12272</td>\n",
       "      <td>7305</td>\n",
       "      <td>BSvw4QVBkgT</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>mycosmolook, eponymousview, instalifo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Είμαι έτοιμη για αλλαγές και είμαι σίγουρη ότι...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1153</td>\n",
       "      <td>BSvw4QVBkgT.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>oiko10</td>\n",
       "      <td>13458</td>\n",
       "      <td>3394</td>\n",
       "      <td>BSx-L0mFeXl</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>kai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#kai kapos etsi ta proina ksipnimata...apoktan...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8366</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>8933</td>\n",
       "      <td>BSx-L0mFeXl.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>giannis_kritikos</td>\n",
       "      <td>18106</td>\n",
       "      <td>4048</td>\n",
       "      <td>BTTS_yjjVqJ</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Έτσι λοιπόν με ένα χαμόγελο ζει πάντα στις καρ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>657</td>\n",
       "      <td>BTTS_yjjVqJ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>mananastasakis</td>\n",
       "      <td>14440</td>\n",
       "      <td>5072</td>\n",
       "      <td>BTGEzKjFGUY</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>prespes, greece, griechenland, grecia, grèce, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>🇬🇷 #prespes #greece #griechenland #grecia #grè...</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>9243</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1013</td>\n",
       "      <td>BTGEzKjFGUY.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15715 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              username  num_followers  num_followings      post_id  \\\n",
       "0     leanna_markoglou          23791             615  BTJVjFOAZRC   \n",
       "1       jls_by_dimitra          14001            1673  BSnouCMl9dx   \n",
       "2       cookingnetwork          15040            3415  BStIhYmAa4Z   \n",
       "3      annamariabarouh          12761              42  BSzRv3gD9Yx   \n",
       "4          olgafarmaki         188519             997  BTPQT0Hl4pk   \n",
       "...                ...            ...             ...          ...   \n",
       "3138     twinsfashionn          17690            4121  BTNBi0cBapl   \n",
       "3139      dorisliapata          12272            7305  BSvw4QVBkgT   \n",
       "3140            oiko10          13458            3394  BSx-L0mFeXl   \n",
       "3141  giannis_kritikos          18106            4048  BTTS_yjjVqJ   \n",
       "3142    mananastasakis          14440            5072  BTGEzKjFGUY   \n",
       "\n",
       "      day_of_week  hour                                           hashtags  \\\n",
       "0               5    15  makeup, hairstyle, youmagazine, photoshooting,...   \n",
       "1               6    13                                                NaN   \n",
       "2               1    16  puremagic, kayak_ice_cream, icecream, lemon, l...   \n",
       "3               4     1      easter, pastel, cupcakes, adorable, delicious   \n",
       "4               7    22  clubc, reebokgreece, sneakers, sparkle, detail...   \n",
       "...           ...   ...                                                ...   \n",
       "3138            7     1     twinsfashion, invernotwins, bonslooks, shopnow   \n",
       "3139            2    17              mycosmolook, eponymousview, instalifo   \n",
       "3140            3    13                                                kai   \n",
       "3141            2    12                                                NaN   \n",
       "3142            4     9  prespes, greece, griechenland, grecia, grèce, ...   \n",
       "\n",
       "          mentions                                            caption  \\\n",
       "0              NaN  My beauty friend.!! #makeup #hairstyle #youmag...   \n",
       "1              NaN  Πενταπλο βραχιολι \"χειροπεδα \" με μαγνητικό κο...   \n",
       "2              NaN  Lemon Grass Ice Cream 🍋 #puremagic #kayak_ice_...   \n",
       "3              NaN  Easter is coming#Easter#pastel #cupcakes #ador...   \n",
       "4     reebokgreece  Just the right amount of sparkle @reebokgreece...   \n",
       "...            ...                                                ...   \n",
       "3138           NaN  Colete faux fur maravideuso 💗 SHOP NOW 📲www.tw...   \n",
       "3139           NaN  Είμαι έτοιμη για αλλαγές και είμαι σίγουρη ότι...   \n",
       "3140           NaN  #kai kapos etsi ta proina ksipnimata...apoktan...   \n",
       "3141           NaN  Έτσι λοιπόν με ένα χαμόγελο ζει πάντα στις καρ...   \n",
       "3142           NaN  🇬🇷 #prespes #greece #griechenland #grecia #grè...   \n",
       "\n",
       "      num_hashtags  num_mentions  hashtag_score  sentiment_score  num_likes  \\\n",
       "0                9             0          60654           1.6580        521   \n",
       "1                0             0              0           1.7633        401   \n",
       "2               10             0          51521           1.0000        108   \n",
       "3                5             0          37419           1.0000        250   \n",
       "4                7             1          25564           1.4215       5168   \n",
       "...            ...           ...            ...              ...        ...   \n",
       "3138             4             0              0           1.0000         92   \n",
       "3139             3             0              0           1.0000       1153   \n",
       "3140             1             0           8366           1.0000       8933   \n",
       "3141             0             0              0           1.0000        657   \n",
       "3142            30             0           9243           1.0000       1013   \n",
       "\n",
       "           image_name  \n",
       "0     BTJVjFOAZRC.jpg  \n",
       "1     BSnouCMl9dx.jpg  \n",
       "2     BStIhYmAa4Z.jpg  \n",
       "3     BSzRv3gD9Yx.jpg  \n",
       "4     BTPQT0Hl4pk.jpg  \n",
       "...               ...  \n",
       "3138  BTNBi0cBapl.jpg  \n",
       "3139  BSvw4QVBkgT.jpg  \n",
       "3140  BSx-L0mFeXl.jpg  \n",
       "3141  BTTS_yjjVqJ.jpg  \n",
       "3142  BTGEzKjFGUY.jpg  \n",
       "\n",
       "[15715 rows x 15 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_addons.metrics import RSquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_384\\3056296733.py:47: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(seqGenerator(X_train, y_train, batch_size, 'All posts', temp_df), steps_per_epoch=trainingset_size // batch_size, epochs=25, callbacks=[losshistory])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " 400/1571 [======>.......................] - ETA: 1:05:42 - loss: 13600545.0000 - r_square: 0.4904 - mean_squared_error: 13600545.0000 - mean_absolute_error: 1602.7261 - mean_absolute_percentage_error: 227.6815"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nFileNotFoundError: No such file: 'f:\\Needed stuff\\Computer Science\\Research stuff\\Finale\\All posts\\BTBv56mlqR0.jpg'\nTraceback (most recent call last):\n\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 268, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py\", line 917, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_384\\3584783668.py\", line 16, in seqGenerator\n    img = io.imread(image_path)\n          ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\skimage\\io\\_io.py\", line 53, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\skimage\\io\\manage_plugins.py\", line 205, in call_plugin\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py\", line 11, in imread\n    out = np.asarray(imageio_imread(*args, **kwargs))\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\imageio\\v3.py\", line 53, in imread\n    with imopen(uri, \"r\", **plugin_kwargs) as img_file:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\imageio\\core\\imopen.py\", line 113, in imopen\n    request = Request(uri, io_mode, format_hint=format_hint, extension=extension)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\imageio\\core\\request.py\", line 247, in __init__\n    self._parse_uri(uri)\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\imageio\\core\\request.py\", line 407, in _parse_uri\n    raise FileNotFoundError(\"No such file: '%s'\" % fn)\n\nFileNotFoundError: No such file: 'f:\\Needed stuff\\Computer Science\\Research stuff\\Finale\\All posts\\BTBv56mlqR0.jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_7427]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m\n\u001b[0;32m     45\u001b[0m losshistory \u001b[39m=\u001b[39m LossHistory()\n\u001b[1;32m---> 47\u001b[0m model\u001b[39m.\u001b[39;49mfit_generator(seqGenerator(X_train, y_train, batch_size, \u001b[39m'\u001b[39;49m\u001b[39mAll posts\u001b[39;49m\u001b[39m'\u001b[39;49m, temp_df), steps_per_epoch\u001b[39m=\u001b[39;49mtrainingset_size \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m batch_size, epochs\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[losshistory])\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:2810\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2798\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2799\u001b[0m \n\u001b[0;32m   2800\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2801\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2802\u001b[0m \u001b[39m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2803\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2804\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2805\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2806\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2807\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2808\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   2809\u001b[0m )\n\u001b[1;32m-> 2810\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   2811\u001b[0m     generator,\n\u001b[0;32m   2812\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   2813\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   2814\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2815\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   2816\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   2817\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   2818\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   2819\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   2820\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   2821\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   2822\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   2823\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   2824\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m   2825\u001b[0m )\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnknownError\u001b[0m: Graph execution error:\n\nFileNotFoundError: No such file: 'f:\\Needed stuff\\Computer Science\\Research stuff\\Finale\\All posts\\BTBv56mlqR0.jpg'\nTraceback (most recent call last):\n\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 268, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py\", line 917, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_384\\3584783668.py\", line 16, in seqGenerator\n    img = io.imread(image_path)\n          ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\skimage\\io\\_io.py\", line 53, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\skimage\\io\\manage_plugins.py\", line 205, in call_plugin\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py\", line 11, in imread\n    out = np.asarray(imageio_imread(*args, **kwargs))\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\imageio\\v3.py\", line 53, in imread\n    with imopen(uri, \"r\", **plugin_kwargs) as img_file:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\imageio\\core\\imopen.py\", line 113, in imopen\n    request = Request(uri, io_mode, format_hint=format_hint, extension=extension)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\imageio\\core\\request.py\", line 247, in __init__\n    self._parse_uri(uri)\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\imageio\\core\\request.py\", line 407, in _parse_uri\n    raise FileNotFoundError(\"No such file: '%s'\" % fn)\n\nFileNotFoundError: No such file: 'f:\\Needed stuff\\Computer Science\\Research stuff\\Finale\\All posts\\BTBv56mlqR0.jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_7427]"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 256\n",
    "CHANNELS = 3\n",
    "\n",
    "#Convolutional neural network for images\n",
    "image_input = Input(shape=(IMAGE_SIZE,IMAGE_SIZE,CHANNELS), name='image_input')\n",
    "image_nn = Conv2D(4, (5,5), activation='relu')(image_input)\n",
    "image_nn = Conv2D(16, (3,3), activation='relu')(image_input)\n",
    "image_nn = MaxPooling2D(pool_size=(2,2))(image_nn)\n",
    "image_nn = Conv2D(32, (3,3), activation='relu')(image_nn)\n",
    "image_nn = Conv2D(64, (3,3), activation='relu')(image_nn)\n",
    "image_nn = MaxPooling2D(pool_size=(2,2))(image_nn)\n",
    "image_nn = Conv2D(128, (3,3), activation='relu')(image_nn)\n",
    "image_nn = MaxPooling2D(pool_size=(2,2))(image_nn)\n",
    "image_nn = Dropout(0.2)(image_nn)\n",
    "image_nn = Conv2D(256, (3,3), activation='relu')(image_nn)\n",
    "image_nn = MaxPooling2D(pool_size=(2,2))(image_nn)\n",
    "image_nn = Dropout(0.2)(image_nn)\n",
    "image_nn = Flatten()(image_nn)\n",
    "\n",
    "#Neural network for user data and image metadata\n",
    "data_input = Input(shape=(X_train.shape[1],), name='data_input')\n",
    "data_nn = Dense(10, activation='relu')(data_input)\n",
    "\n",
    "#Merge of the networks and last part of the network\n",
    "output_nn = keras.layers.concatenate([image_nn, data_nn])\n",
    "output_nn = Dense(500, activation='relu')(output_nn)\n",
    "output_nn = Dropout(0.1)(output_nn)\n",
    "output_nn = Dense(10, activation='relu')(output_nn)\n",
    "output_nn = Dense(1, name='output')(output_nn)\n",
    "\n",
    "#Model definition\n",
    "model = Model(inputs=[image_input, data_input], outputs = [output_nn])\n",
    "\n",
    "# Define custom metrics\n",
    "mse = tf.keras.metrics.MeanSquaredError()\n",
    "mae = tf.keras.metrics.MeanAbsoluteError()\n",
    "mape = tf.keras.metrics.MeanAbsolutePercentageError()\n",
    "\n",
    "# Compile model with the custom metrics\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=[RSquare(), mse, mae, mape])\n",
    "\n",
    "# Fit the model\n",
    "trainingset_size = len(X_train)\n",
    "batch_size = 8\n",
    "losshistory = LossHistory()\n",
    "\n",
    "model.fit_generator(seqGenerator(X_train, y_train, batch_size, 'All posts', temp_df), steps_per_epoch=trainingset_size // batch_size, epochs=25, callbacks=[losshistory])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
